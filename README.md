# Personalized Assignment Recommendation System using Deep Reinforcement Learning

This project implements a personalized assignment recommendation system designed to adapt to each student's evolving learning needs. By leveraging reinforcement learning and knowledge tracing, the system aims to provide programming problem suggestions that are both challenging and pedagogically sound.



---

## Overview

The goal of this system is to recommend assignments tailored to students based on their historical performance, ensuring consistent learning progression. The recommender uses a Double Deep Q-Network (DDQN) agent trained in a custom-built reinforcement learning environment, incorporating student interaction history and problem metadata such as difficulty and topic tags.

---

## Key Features

- **Knowledge-Aware Recommendations**  
  Recommendations are guided by a graph-based knowledge tracing model that captures student progress over time.

- **Custom RL Environment**  
  Simulates realistic student-problem interactions and adapts based on a student’s learning trajectory.

- **Dynamic Reward Function**  
  Balances between review and discovery, topic smoothness, and difficulty transitions to ensure pedagogically sound recommendations.

- **DDQN Agent**  
  Learns optimal recommendation strategies using experience replay, target networks, and an epsilon-greedy exploration policy.

---

## Data Collection

The student performance data was extracted using the [Codeforces API](https://codeforces.com/apiHelp), which provides access to users' submission history. For each student (user), I retrieved all past problem submissions, including problem IDs, verdicts (correct/incorrect), difficulty ratings, and associated tags. This historical data served as the foundation for modeling individual learning trajectories and building the personalized recommendation environment.

---

## State Representation

Each student’s learning state is dynamically represented using a graph-based knowledge tracing model composed of:

- **Graph Problem Embedding (`qt-1`)**  
  Generated by a Graph Convolutional Network (GCN) based on the problem’s topic structure.

- **LSTM Hidden State (`ht`)**  
  Captures the temporal sequence of problem-solving history.

- **Recap Module (`rt`)**  
  Applies an attention mechanism to emphasize relevant past interactions.

These components are combined into a high-dimensional vector summarizing the student’s knowledge state and learning trajectory.

---

## Reward Function

The reward function encourages effective learning through:

1. **Review and Discover**
   - Rewards discovering new topics after successful attempts.
   - Encourages reviewing unmastered topics.

2. **Knowledge Point Smoothness**
   - Penalizes abrupt changes in topic coverage.
   - Rewards gradual transitions across similar topics.

3. **Difficulty Smoothness**
   - Uses an arctangent function to encourage consistent difficulty progression.

**Overall Reward**  
A weighted sum of the above components:
$$
r = \beta_1 r_1 + \beta_2 r_2 + \beta_3 r_3
$$

Where the weights can be tuned to prioritize different aspects of learning.

---

## The Agent

The DDQN agent:

- Observes the student's current knowledge state.
- Selects the next assignment to recommend.
- Receives reward feedback from the environment.
- Learns using:
  - A **policy network** for action selection.
  - A **target network** for stable Q-value updates.
  - An **experience replay buffer** for efficient learning.
  - An **epsilon-greedy strategy** to balance exploration and exploitation.


---

## References 

This project is inspired by the following research works that guided the design of the recommendation framework, especially the use of deep reinforcement learning and graph-based knowledge tracing:

- **[Learning Style Integrated Deep Reinforcement Learning Framework for Programming Problem Recommendation in Online Judge System](https://link.springer.com/article/10.1007/s44196-022-00176-4)** This work presents a deep reinforcement learning-based recommendation system that personalizes programming problem recommendations by integrating learners' learning styles.

- **[GIKT: A Graph-based Interaction Model for Knowledge Tracing](https://arxiv.org/abs/2009.05991)** GIKT addresses limitations in prior knowledge tracing models by introducing a graph-based model that captures high-order question-skill correlations and long-term dependencies in student histories.

These papers inspired the incorporation of graph-based embeddings, the design of the custom reinforcement learning environment, and the structure of the reward function and recommendation policy.
